{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776d8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def create_test_artifacts():\n",
    "    \"\"\"\n",
    "    Creates synthetic data and fitted models for testing ML functions.\n",
    "\n",
    "    Returns:\n",
    "        X_train (DataFrame): Training features\n",
    "        X_test (DataFrame): Test features\n",
    "        y_train (Series): Training labels (encoded as 'N', 'Y')\n",
    "        y_test (Series): Test labels (encoded as 'N', 'Y')\n",
    "        models (dict): Dictionary of fitted pipelines\n",
    "    \n",
    "    Example:\n",
    "        To use this function, simply call:\n",
    "            X_train, X_test, y_train, y_test, models = create_test_artifacts()\n",
    "        \n",
    "        Models included:\n",
    "            - Dummy: Dummy Classifier\n",
    "            - SVM: SVM RBF\n",
    "            - KNN: KNN\n",
    "            - DecisionTree: Decision Tree\n",
    "            - RandomForest: Random Forest\n",
    "        \n",
    "        To select a specific model for testing, use models dictionary:\n",
    "            single_model = models[\"RandomForest\"]\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    # Generate Synthetic Data\n",
    "    # Create 200 samples with 5 numeric features\n",
    "    X, y = make_classification(\n",
    "        n_samples=200, \n",
    "        n_features=5, \n",
    "        n_informative=3,\n",
    "        n_redundant=0, \n",
    "        random_state=123\n",
    "    )\n",
    "\n",
    "    # Wrap in Pandas\n",
    "    X_df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(5)])\n",
    "    \n",
    "    # Map 0/1 to 'N'/'Y' so fbeta_score(pos_label=\"Y\") works\n",
    "    y_series = pd.Series(y).map({0: 'N', 1: 'Y'})\n",
    "    y_series.name = \"churn\"\n",
    "\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_df, y_series, test_size=0.3, random_state=123\n",
    "    )\n",
    "\n",
    "    # Define Models and Pipelines\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    models = {\n",
    "        \"Dummy\": make_pipeline(scaler, DummyClassifier(strategy=\"most_frequent\")),\n",
    "        \"SVM\": make_pipeline(scaler, SVC(kernel=\"rbf\", probability=True, random_state=123)),\n",
    "        \"KNN\": make_pipeline(scaler, KNeighborsClassifier(n_neighbors=3)),\n",
    "        \"DecisionTree\": make_pipeline(scaler, DecisionTreeClassifier(max_depth=5, random_state=123)),\n",
    "        \"RandomForest\": make_pipeline(scaler, RandomForestClassifier(n_estimators=10, random_state=123))\n",
    "    }\n",
    "\n",
    "    # Fit the models\n",
    "    # Test functions expect fitted estimators\n",
    "    for name, pipe in models.items():\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4622e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, models = create_test_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e515999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cv_metric_compare(models_dict, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    Evaluates multiple models using Cross-Validation and returns a metric/scorer comparison DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models_dict : dict\n",
    "        Dictionary of {model_name: pipeline_object}. \n",
    "        Note: Models do not need to be fitted beforehand.\n",
    "    X : DataFrame\n",
    "        Features (Training set or full dataset).\n",
    "    y : Series\n",
    "        Labels (Training set or full dataset).\n",
    "    cv : int\n",
    "        Number of cross-validation folds (default 5).\n",
    "\n",
    "    Scorers Evaluated\n",
    "    -----------------\n",
    "    - accuracy\n",
    "    - precision (pos_label=\"Y\")\n",
    "    - recall (pos_label=\"Y\")\n",
    "    - f1 (pos_label=\"Y\")\n",
    "    - roc_auc (if model supports predict_proba)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe : pandas.DataFrame\n",
    "        Dataframe containing model name and mean evaluation metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define Scorers that handle specific pos_label=\"Y\"\n",
    "    scorers = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score, pos_label=\"Y\"),\n",
    "        'recall': make_scorer(recall_score, pos_label=\"Y\"),\n",
    "        'f1': make_scorer(f1_score, pos_label=\"Y\"),\n",
    "    }\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    for name, model in models_dict.items():\n",
    "        # Check if model supports probabilities for ROC-AUC\n",
    "        # We need a separate handling for ROC AUC because it requires probabilities, not just predictions\n",
    "        current_scorers = scorers.copy()\n",
    "        \n",
    "        # Only add ROC_AUC if the model supports predict_proba\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            # Note: For string labels, we need to ensure the scorer knows which class is positive.\n",
    "            # response_method='predict_proba' is handled by make_scorer automatically if configured,\n",
    "            # but standard 'roc_auc' string in sklearn often assumes 0/1 or specific ordering.\n",
    "            # We create a custom scorer for safety with string labels.\n",
    "            def custom_roc(y_true, y_prob):\n",
    "                 # This helper is needed if y is \"Y\"/\"N\" to map it for calculation\n",
    "                 y_true_num = (y_true == \"Y\").astype(int)\n",
    "                 return roc_auc_score(y_true_num, y_prob)\n",
    "            \n",
    "            # We tell sklearn to pass the probability of the positive class\n",
    "            current_scorers['roc_auc'] = make_scorer(custom_roc, response_method=\"predict_proba\")\n",
    "\n",
    "        # Run Cross-Validation\n",
    "        cv_results = cross_validate(\n",
    "            model, \n",
    "            X, \n",
    "            y, \n",
    "            cv=cv, \n",
    "            scoring=current_scorers,\n",
    "            n_jobs=-1 # Use all CPU cores for speed\n",
    "        )\n",
    "\n",
    "        # Aggregate Results (Take the Mean of the folds)\n",
    "        metrics = {\"Model\": name}\n",
    "        for metric_name in current_scorers.keys():\n",
    "            # cross_validate returns keys like 'test_accuracy', 'test_f1', etc.\n",
    "            key = f\"test_{metric_name}\"\n",
    "            if key in cv_results:\n",
    "                metrics[metric_name] = np.mean(cv_results[key])\n",
    "            else:\n",
    "                metrics[metric_name] = np.nan\n",
    "\n",
    "        results_list.append(metrics)\n",
    "\n",
    "    # 5. Format Output\n",
    "    comparison_df = pd.DataFrame(results_list).set_index(\"Model\")\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef4686b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wnsong/miniforge3/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/wnsong/miniforge3/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roc_auc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "46e9aa97-d656-4288-9d2b-671ce1b79740",
       "rows": [
        [
         "Dummy",
         "0.5214285714285714",
         "0.5214285714285714",
         "1.0",
         "0.6852713178294574",
         "0.5"
        ],
        [
         "SVM",
         "0.7571428571428571",
         "0.7630398246255025",
         "0.8095238095238095",
         "0.7721620179480961",
         "0.8690162218733647"
        ],
        [
         "KNN",
         "0.7142857142857142",
         "0.716078431372549",
         "0.7666666666666667",
         "0.7351046135918217",
         "0.7805128205128204"
        ],
        [
         "DecisionTree",
         "0.7714285714285714",
         "0.8045143745143744",
         "0.7514285714285716",
         "0.7716914298983264",
         "0.8132940868655153"
        ],
        [
         "RandomForest",
         "0.7357142857142858",
         "0.7590336134453782",
         "0.7542857142857142",
         "0.737825787567046",
         "0.8485897435897437"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685271</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.763040</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.772162</td>\n",
       "      <td>0.869016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.716078</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>0.780513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.804514</td>\n",
       "      <td>0.751429</td>\n",
       "      <td>0.771691</td>\n",
       "      <td>0.813294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.759034</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>0.737826</td>\n",
       "      <td>0.848590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  precision    recall        f1   roc_auc\n",
       "Model                                                          \n",
       "Dummy         0.521429   0.521429  1.000000  0.685271  0.500000\n",
       "SVM           0.757143   0.763040  0.809524  0.772162  0.869016\n",
       "KNN           0.714286   0.716078  0.766667  0.735105  0.780513\n",
       "DecisionTree  0.771429   0.804514  0.751429  0.771691  0.813294\n",
       "RandomForest  0.735714   0.759034  0.754286  0.737826  0.848590"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv_metric_compare(models, X_train, y_train, cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
